# -*- coding: utf-8 -*-
"""HawkEyeInit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zm2iVJkBe1z9Xs8meb1aZkDETcR6RBYt
"""

# %load_ext autotime

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import os
import pathlib
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from zipfile import ZipFile

"""imports, not something special"""
#PATH = "C:\Users\ofirs\Desktop\2019VisionImages"
with ZipFile('C:/Users/ofirs/Desktop/2019VisionImages', 'r') as zipObj:
  zipObj.extractall()
  PATH = '/content/'

"""import zipfile from Colab 

**Caution:  need to change when using raspi**
"""

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')
#train
train_CargoAngled_dir = os.path.join(train_dir , 'Cargo Angled')
train_CargoLine_dir = os.path.join(train_dir , 'Cargo Line')
train_CargoSide_dir = os.path.join(train_dir , 'Cargo Side')
train_CargoStraight_dir = os.path.join(train_dir , 'Cargo Straight')
train_LoadingAngle_dir = os.path.join(train_dir , 'Loading Angle')
train_LoadingStraight_dir = os.path.join(train_dir , 'Loading Straight')
train_RocketBallStraight_dir = os.path.join(train_dir , 'RocketBall Straight')
train_RocketPanel_dir = os.path.join(train_dir , 'RocketPanel')
#validation
validation_CargoAngled_dir = os.path.join(validation_dir , 'Cargo Angled')
validation_CargoLine_dir = os.path.join(validation_dir , 'Cargo Line')
validation_CargoSide_dir = os.path.join(validation_dir , 'Cargo Side')
validation_CargoStraight_dir = os.path.join(validation_dir , 'Cargo Straight')
validation_LoadingAngle_dir = os.path.join(validation_dir , 'Loading Angle')
validation_LoadingStraight_dir = os.path.join(validation_dir , 'Loading Straight')
validation_RocketBallStraight_dir = os.path.join(validation_dir , 'RocketBall Straight')
validation_RocketPanel_dir = os.path.join(validation_dir , 'RocketPanel')

"""Here we create vars for all paths of labels"""

#train lengths
len_CargoAngled_tr = len(os.listdir(train_CargoAngled_dir))
len_CargoLine_tr = len(os.listdir(train_CargoLine_dir))
len_CargoSide_tr = len(os.listdir(train_CargoSide_dir))
len_CargoStraight_tr = len(os.listdir(train_CargoStraight_dir))
len_LoadingAngle_tr = len(os.listdir(train_LoadingAngle_dir))
len_LoadingStraight_tr = len(os.listdir(train_LoadingStraight_dir))
len_RocketBallStraight_tr = len(os.listdir(train_RocketBallStraight_dir))
len_RocketPanel_tr = len(os.listdir(train_RocketPanel_dir))
total_train = len_CargoAngled_tr + len_CargoLine_tr + len_CargoSide_tr + len_CargoStraight_tr + len_LoadingAngle_tr + len_LoadingStraight_tr + len_RocketBallStraight_tr + len_RocketPanel_tr

#validation lenghts
len_CargoAngled_val = len(os.listdir(validation_CargoAngled_dir))
len_CargoLine_val = len(os.listdir(validation_CargoLine_dir))
len_CargoSide_val = len(os.listdir(validation_CargoSide_dir))
len_CargoStraight_val = len(os.listdir(validation_CargoStraight_dir))
len_LoadingAngle_val = len(os.listdir(validation_LoadingAngle_dir))
len_LoadingStraight_val = len(os.listdir(validation_LoadingStraight_dir))
len_RocketBallStraight_val = len(os.listdir(validation_RocketBallStraight_dir))
len_RocketPanel_val = len(os.listdir(validation_RocketPanel_dir))
total_val = len_CargoAngled_val + len_CargoLine_val + len_CargoSide_val + len_CargoStraight_val + len_LoadingAngle_val + len_LoadingStraight_val + len_RocketBallStraight_val + len_RocketPanel_val

#prints
print("total Cargo Images: " + str((len_CargoAngled_tr + len_CargoAngled_val + len_CargoLine_tr + len_CargoLine_val + len_CargoSide_tr + len_CargoSide_val + len_CargoStraight_tr + len_CargoStraight_val)))
print("total Loading Images: " + str((len_LoadingAngle_tr + len_LoadingAngle_val + len_LoadingStraight_tr + len_LoadingStraight_val)))
print("total RocketBall Images: " + str((len_RocketBallStraight_tr + len_RocketBallStraight_val)))

"""Know your data: collect and print information about data"""

batch_size = 128
epochs = 15
IMG_HEIGHT = 240
IMG_WIDTH = 320

train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data
validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data

train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')
val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,
                                                              directory=validation_dir,
                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                              class_mode='binary')

"""make the generators for train and val"""

sample_training_images, _ = next(train_data_gen)
# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()
  
plotImages(sample_training_images[:5])

"""(I Think its optional)
prints part of the images

### _create the model_
"""

model_new = Sequential([
    Conv2D(16, 3, padding='same', activation='relu', 
           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),
    MaxPooling2D(),
    Dropout(0.2),
    Conv2D(32, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(64, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Dropout(0.2),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(1)
])

"""### _Compile it_"""

model_new.compile(optimizer='adam',
                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                  metrics=['accuracy'])

model_new.summary()

"""### _Train it_"""

history = model_new.fit_generator(
    train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size
)
